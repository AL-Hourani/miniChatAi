import torch
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

MODEL_HF = "jaafar-ai/miniChat"

model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_HF)
tokenizer = AutoTokenizer.from_pretrained(MODEL_HF)


allowed_keywords = [
    "سكري", "السكري", "داء السكري", "مرض السكري", "مرض السكر", "السكر",
    "النوع الأول", "النوع الثاني", "سكري الحمل", "سكر الأطفال", "سكر المراهقين",
    "سكر", "غلوكوز", "جلوكوز", "فركتوز", "الهيموغلوبين", "HbA1c", "التراكمي",
    "تحليل السكر", "قياس السكر", "شرائط السكر", "جهاز قياس", "مستوى السكر",
    "انسولين", "أنسولين", "إبرة أنسولين", "حقن أنسولين", "مضخة أنسولين",
    "جلوكوفاج", "غلوكوفاج", "ميتفورمين", "أماريل", "دياميكرون", "أكتوس",
    "فورسيغا", "جاردينس", "فكتوزا", "اوزيمبك", "انفوكانا",
    "حبوب السكر", "دواء السكر", "أدوية السكري",
    "أعراض", "عطش", "كثرة التبول", "تبول متكرر", "جوع", "فقدان وزن",
    "إرهاق", "تعب", "دوخة", "غيبوبة السكر", "تشويش الرؤية", "التهابات", "التئام الجروح",
    "مضاعفات", "اعتلال شبكية", "اعتلال الكلى", "أمراض الكلى", "الفشل الكلوي",
    "اعتلال الأعصاب", "القدم السكرية", "بتر القدم",
    "جلطات", "قلب", "تصلب الشرايين", "السكتة الدماغية", "ضغط الدم", "الكوليسترول",
    "حمية", "نظام غذائي", "رجيم", "تغذية", "نشويات", "كربوهيدرات",
    "سكريات", "دهون", "بروتين", "وجبات", "أطعمة مسموحة", "أطعمة ممنوعة",
    "رياضة", "مشي", "تمارين", "نشاط", "وزن", "سمنة", "سعرات", "حرق الدهون",
    "حمل", "حامل", "سكري الحمل", "رضاعة", "أطفال", "مراهق", "كبار السن",
    "إبرة السكر", "حقنة السكر", "علاج السكر", "دواء السكر", "حبوب السكر",
    "هبوط السكر", "انخفاض السكر", "ارتفاع السكر", "فرط سكر الدم", "نقص سكر الدم",
    "حماض كيتوني", "كيتونات", "طبيب غدد", "طبيب سكري", "متابعة السكر"
]

def safe_generate_answer(model, tokenizer, question, allowed_keywords, max_len=64, num_beams=4):
    if not any(keyword in question for keyword in allowed_keywords):
        return "عذرًا، أنا مخصص للإجابة فقط عن أسئلة مرض السكري."

    model.eval()
    inputs = tokenizer(
        question,
        return_tensors="pt",
        truncation=True,
        padding=True
    )
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_length=max_len,
            num_beams=num_beams,
            early_stopping=True
        )
    return tokenizer.decode(outputs[0], skip_special_tokens=True)



